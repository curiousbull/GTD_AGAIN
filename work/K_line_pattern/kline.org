#+TITLE: K 线形态匹配代码解读
#+AUTHOR: 胡琛

* 主函数

  #+BEGIN_SRC ipython
    if __name__ == '__main__':
      lines_arr = None
      data = np.loadtxt('pattern5_cluster.txt')
      for i in range(data.shape[0]):
        pattern = data[i].reshape((5,5)).T*10
        p = Pattern(pattern)
        patterns = p.match_patterns()
        if patterns is np.NAN:
          continue
        lines = p.save_pattern(patterns,'./pattern' + str(i))
        if lines_arr == None:
          lines_arr = lines[np.newaxis,:,:]
        else:
          lines_arr = np.vstack([lines_arr,lines[np.newaxis,:,:]])
      order_lines(lines_arr)
  #+END_SRC
  
  1. 'pattern5_cluster.txt' 对应的数据结构是每 5 根 Bar 的开、高、低、收、量 5 个数据，
     相应的，读取的 'txt' 文档每行有 25 个数据，需要进行处理

     #+BEGIN_SRC ipython
       for i in range(data.shape[0]):
           pattern = data[i].reshape((5,5)).T*10
     #+END_SRC

  2. 'pattern' match 的方式是通过相关系数来比较，返回的 'pattern' 是 =numpy.array= 格式，
     返回的是符合条件的股票的信息

* Pattern 类的解读

  1. 初始化

     #+BEGIN_SRC ipython
       def __init__(self,data):
           self.data = data
           self.data_length = self.data.shape[0]
           self.distribution_tol = None
           self.__future_length = self.data_length * 2
           self.__patterns = None
           self.__conn = self.__connect_database()
           self.__distribution_days = None
           self.__statistics = None
           self.__EPs = 0
           self.__clusters = None
           self.__percent = None
     #+END_SRC

  2. pattern 匹配

     #+BEGIN_SRC ipython
       def match_patterns(self,similarity=0.7):
         '''
         match patterns in history data
         return the most similar 100 patterns whose similarity reach 0.7
         return a 3d array
         '''
           try:
             self.__clear_db_correlation()
             self.__match_stocks(similarity)
             similarities = self.__get_all_similarities()
             if similarities.shape[0] == 0:
               return None
             patterns = self.__get_patterns(similarities)
             self.__predict(patterns)
             return patterns
           finally:
             self.__conn.close()
     #+END_SRC

     1) '__clear_db_correlation()' ： 清除表内容，同时保持表结构，相比 'DELETE', 'TRUNCATE' 速度更快，
        但是不能恢复

        #+BEGIN_SRC ipython
          def __clear_db_correlation(self):
              cur = self.__conn.cursor()
              sql = 'truncate table correlation1'
              cur.execute(sql)
              cur.close()
        #+END_SRC

     2) '__match_stocks(similarity)'

        #+BEGIN_SRC ipython
          def __match_stocks(self,similarity_pro):
              sql = 'insert into correlation1 values(%s,%s,%s)'
              cur = self.__conn.cursor()
              for id in range(117,500,1):
                if (id+1)%100==0:
                  print(id+1)
                  self.__conn.commit()
                data = self.__get_data_from_symbol_id(id+1)
                for j in range(data.shape[0] - self.data_length + 1):
                  similarity = self.__count_similarity(self.data,data[j:j + self.data_length,1:6])
                  if similarity > similarity_pro*6:
                    parameters = (str(similarity),str(data[j,0]),str(id+1))
                    cur.execute(sql,parameters)
              self.__conn.commit()
              cur.close()
        #+END_SRC

        - '__get_data_from_symbol_id(self, id)' ：取出 id 对应的开、高、低、收、量的股票日线数据

          #+BEGIN_SRC ipython
            def __get_data_from_symbol_id(self,id):
                sql = 'select id,open_price,high_price,low_price,close_price,volume from stock_daily where symbol_id=%s and price_date<\'2016-01-01\' \
                and price_date>\'2010-01-01\''%id
                cur = self.__conn.cursor()
                cur.execute(sql)
                data = np.array(cur.fetchall(),dtype=np.float64)
                cur.close()
                return data
          #+END_SRC

        - '__count_similarity(self, arr1, arr2)' ： 比较两个序列的相关度，其中，量对应的相关系数
          权重设为 2.

          #+BEGIN_SRC ipython
            def __count_similarity(self,arr1,arr2):
                cor_open  = self.__correlation(arr1[:,0],arr2[:,0])
                cor_high  = self.__correlation(arr1[:,1],arr2[:,1])
                cor_low   = self.__correlation(arr1[:,2],arr2[:,2])
                cor_close = self.__correlation(arr1[:,3],arr2[:,3])
                cor_volume = self.__correlation(arr1[:,4],arr2[:,4])
                similarity = cor_open+cor_high+cor_low+cor_close+cor_volume*2
                return similarity
          #+END_SRC

        - '__correlation(self, series1, series2)' ：相关系数计算

          #+BEGIN_SRC ipython
            def __correlation(self,series1,series2):
                n = series1.size
                numerator = np.sum(series1*series2)*n - series1.sum()*series2.sum()
                denominator = np.sqrt(n*np.sum(series1*series1)-series1.sum()
                                      *series1.sum())*np.sqrt(n*np.sum(series2*series2)-series2.sum()*series2.sum())
                result = numerator/denominator
                if result == np.inf:
                  result = 0
                return result
          #+END_SRC

          相关系数的计算公式：

            \begin{equation}
              \begin{array}{lcl}
              r &=& \frac{\sum\limits^n_{i=1}(x_i-\bar{x})(y_i-\bar{y})}
              {\sqrt{\sum\limits^n_{i=1}}(x_i-\bar{x})^2\sum\limits^n_{i=1}(y_i-\bar{y})^2}}\\
                &=&\frac{n\sum\limits^n_{i=1}x_iy_i-\sum\limits^n_{i=1}x_i\sum\limits^n_{i=1}y_i}
                    {\sqrt{n\sum\limits^n_{i=1}x_i^2-(\sum\limits^n_{i=1}x_i)^2}\cdot
                    \sqrt{n\sum\limits^n_{i=1}x_i^2-(\sum\limits^n_{i=1}x_i)^2}}
            \end{equation}

        - 代码块解读：

          #+BEGIN_SRC ipython
            data = self.__get_data_from_symbol_id(id+1)
                  for j in range(data.shape[0] - self.data_length + 1):
                    similarity = self.__count_similarity(self.data,data[j:j + self.data_length,1:6])
                    if similarity > similarity_pro*6:
                      parameters = (str(similarity),str(data[j,0]),str(id+1))
                      cur.execute(sql,parameters)
          #+END_SRC

          从股票 'id' 中取出数据 'data', 对 'data' 中第 'data_length' 开始往后依次计算原始数据 'self.data'
          和 'data[j:j+self.data_length,1:6]' 相关系数，如果相关系数 'similarity > similarity_pro*6', 
          表明相似度符合我们的需求，这里的数字 6 对应的是开高低收量，其中量对应权重是 2 的相似度，
          将对应的相似度 'similarity', 数据起始日期 'data[j:0]' 和股票序号 'id+1'
          写入数据库 'self.__conn.commit()'

     3) '__get_all_similarities(self)' ：取出所有满足 'similarity' 要求的数据，至多取 100 条数据

        #+BEGIN_SRC ipython
          def __get_all_similarities(self):
              cur = self.__conn.cursor()
              sql = 'select * from correlation1 ORDER BY similarity DESC LIMIT 100'
              cur.execute(sql)
              similarities = np.array(cur.fetchall(),dtype=np.float64)
              return similarities
        #+END_SRC

     4) '__get_patterns(self, similarities)' ：取出相应数据对应的开高低收量。

        #+BEGIN_SRC ipython
          def __get_patterns(self,similarities):
              patterns = np.NAN
              cur = self.__conn.cursor()
              sql = 'select open_price,high_price,low_price,close_price,volume from stock_daily where id between %s and %s and symbol_id=%s'
              for i in similarities:
                cur.execute(sql%(i[1],i[1] + self.data_length * 3 - 1,i[2]))
                try:
                  pattern = np.array(cur.fetchall(),dtype=np.float64).reshape(1,self.data_length * 3,5)
                  if patterns is np.NAN:
                    patterns = pattern
                  else:
                    patterns = np.vstack([patterns,pattern])
                  if patterns.shape[0] >= 100:
                    return patterns
                except:
                  pass
              cur.close()
              return patterns
        #+END_SRC

     5) '__predict(self, patterns)' ：

        #+BEGIN_SRC ipython
          def __predict(self,patterns):
            '''
            count the future 2*period day's increment
            '''
              result_tol = np.zeros(self.__future_length)
              EPs = np.zeros((patterns.shape[0],self.__future_length))
              statistics = np.zeros((4,self.__future_length))
              for i in range(patterns.shape[0]):
                close_price = patterns[i,self.data_length-1,3]
                for j in range(self.__future_length):
                  EP = (patterns[i,self.data_length + j,3] - close_price) / close_price
                  EPs[i,j] = EP
                  if patterns[i,self.data_length + j,3] > close_price:
                    result_tol[j] = result_tol[j] + 1

              for i in range(self.__future_length):
                statistics[0,i] = np.mean(EPs[:,i])
                statistics[1,i] = np.var(EPs[:,i])
                statistics[2,i] = sts.kurtosis(EPs[:,i])
                statistics[3,i] = sts.skew(EPs[:,i])
              self.distribution_tol = result_tol/patterns.shape[0]
              self.__statistics = statistics
              self.__EPs = EPs
        #+END_SRC
